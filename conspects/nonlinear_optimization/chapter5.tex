\section{Systems with inputs and outputs}

Study/control systems $\dot{x} = f(x,u)$ with "output" $y(t)=W(x(t))$

\subsection{Sliding mode control}

Motivating example
\begin{equation*}
\dot{x_1} = x_2
\end{equation*}
\begin{equation*}
\dot{x_2} = u \Rightarrow \dot{y} = x_2 + u
\end{equation*}
\begin{equation*}
y = x_1 + x_2
\end{equation*}

Choose:
\begin{equation*}
u =  \left\{
                \begin{array}{ll}
                  -x_2-1, \ \ y > 0\\
                  -x_2+1, \ \ y < 0\\
                  -x_2, \ \ y=0
                \end{array}
              \right. 
\end{equation*}
\begin{equation*}
\Rightarrow \dot y =  \left\{
                \begin{array}{ll}
                  -1, \ \ y > 0\\
                  +1, \ \ y < 0\\
                  0, \ \ y=0
                \end{array}
              \right. 
\end{equation*}

Solutions(Laratheodory) are if $y(0) > 0$, then 
\begin{equation*}
y(t) = \left\{ \begin{array}{ll}
                  y(0) - t, \ \ t \leq y(0)\\
                  0, \ \ t > y(0)
                \end{array}
              \right. 
\end{equation*}
If $y(0) < 0$, then
\begin{equation*}
y(t) = \left\{ \begin{array}{ll}
                  y(0) + t, \ \ t \leq y(0)\\
                  0, \ \ t > -y(0)
                \end{array}
              \right. 
\end{equation*}

%TODO picture

Key property: choose $u$ s.t. $y(t)$ goes to zero in finite time $\Rightarrow x(t)$ tends $\{ (x_1, x_2) \in \mathbb{R}^2 | x_1 +x_2 = 0 \}$ in finite time

Consider dynamics on $S$
\begin{equation*}
\left\{ \begin{array}{l}
                  \dot{x_1} = x_2 (x_2 = -x_1 \ $if$ \  y =1) = -x_1\\
                 \dot{x_2} = u = -x_2
                \end{array}
              \right. 
\end{equation*} 
globally as stable

%TODO picture

Two "phases"
\begin{enumerate}
\item solutions converge to $S$ in finite time
\item solutions converge to zero ("on S") asymptotically
\end{enumerate}
$\leadsto $ "sliding mode" control

Remark: in (1) "finite time convergence is crucial"

General procedure:
\begin{equation*}
\dot{x} = f(x)+g(x)u \\
y = h(x)= s(x)
\end{equation*}
$f: \mathbb{R}^n \to \mathbb{R}^n, \  y : \mathbb{R}^n \to \mathbb{R}^n, \ s: \mathbb{R}^n \to \mathbb{R}$

$u$ - scalar input, $s(x)$ - sliding

single input, single output 

Assumptions: $y$ has relative degree 1, well - defined globally, i.e. $L_gs(x) \neq 0 \ \forall \in \mathbb{R}^n$

Two-step approach:
\begin{enumerate}
\item Bring $x(t)$ to $S := \left \{ x \in \mathbb{R}^n | S(x) = 0 \right\}$ in finite time
\item Have $x(t)$ going to zero asymptotically (on $S$)
\begin{itemize}
\item switching between nodes 1 and 2
\item mode 2 is "sliding mode"
\end{itemize}
\end{enumerate} 

%TODO picture

How are 1 + 2 achieved?
\begin{itemize}
\item Design of sliding manifolds crucial!

Need: For $y(t)=0$ for all $t \geq 0$. All solutions convergeto the origin, i.e., "zero dynamics" have globally asymptotically stable origin.

How? e.g. systems in "regular form"
$x = \left[ \eta \xi \right]'$ 
\begin{equation*}
\begin{array}{l}
     \dot{\eta} = f_1(\eta, \xi)\\
     \dot{\xi} = f_2(\eta, \xi) + g_2(\eta,\xi) u
\end{array}
\end{equation*}
Choose $s(x)=\eta - \phi(\eta)$, where $\phi$ asymptotically stabilizes zero dynamics $\dot{\eta} = f_1(\eta, \phi(\eta))$ (and $\phi(0) = 0$)
Ex. 1.9 in Khalil
\item Converging to sliding manifold in finite time:
$\leadsto \dot{y} = L_fs(x) + L_gs(x)u$, where $L_gs(x) \neq 0$. Obvious choice to render $S$ invariant is $u = - \frac{L_fS(x)}{L_gs(x)}$ (mode 2, behaviour on $S$)

Asin motivating example, add 
\begin{equation*}
\left \{ \begin{array}{ll}
     - \hat{u}/ L_gs(x) & y > 0 \\
     \hat{u} /L_gs(x) & y < 0
\end{array} \right.
\end{equation*}
where $\hat{u} > 0$

\begin{equation*}
 u = - \frac{1}{L_gs(x)}(L_fs(x) + \hat{u}sgn(s(x)))
\end{equation*}
$\leadsto \dot{y} = - \hat{u} sgn(y)$

$\leadsto $ (caratheodory) solutions converge to zero in finite time

$\leadsto x(t)$ converges to $S$ in finite time
\end{itemize}

Control Lyapunov perspective

$V(X) = \frac{1}{2}s(x)^2$
\begin{equation*}
\dot{V}(x) = s(x) \dot{s}(x) = s(x)(L_fs(x)+L_gs(x)u) = -s(x)sgn(s(x))\hat{u} = | s(x)|\hat{u} < 0 for s(x) \neq 0
\end{equation*}

Consider $W = \sqrt{2v} \leadsto^{s \neq 0} \dot{w} = \sqrt{2}, \ \frac{1}{2\sqrt{v}}\dot{v}=-\hat{u}$

$\leadsto w$ converges to 0 in finite time $\Rightarrow V $ converges to 0 in finite time $\Rightarrow S(x(t))$ converges to 0 in finite time.

\begin{Example}
\begin{equation}
\begin{array}{l}
     \dot{x_1} = x_2 + x_1 sin(x_2)\\
     \dot{x_2} = x_2^2 + x_1 + u
\end{array}
\end{equation}
Choose $s(x) = x_2 + 2x_1$, where $+2x_! := \phi(x_1)$ on $S$: $\dot{x_1} = -2x_1 + x_1 sin(-2x_1) \leadsto $ asymptotically stable
\begin{equation*}
\dot{s} = x_2^2 + x_1 + u - 2x_2 -2x_1 sin(x_2) \leadsto u = - (x_2^2 + x_1 -2x_2 -2x_1sin(x_2) + \hat{u}sgn(x_2 -2x_1)), \ \hat{u} > 0
\end{equation*} 
$\leadsto$ yields finite-time convergence to $S$.
\end{Example}

Alternative sliding mode controllers
\begin{equation*}
u = - \frac{1}{L_gs(x)}(L_fs(x) + \hat{u}sgn(s(x))), \ \hat{u} > 0
\end{equation*}

In particular
\begin{equation*}
u = - \frac{1}{L_gs(x)}(L_fs(x) + \hat{u}|L_gs(x)|sgn(s(x)))
\end{equation*}
$\leadsto $ ensure robustness w.r.t. "matched uncertainties"
\begin{equation*}
\dot{x} = f(x) + g(x) \sigma (x) + g(x)u 
\end{equation*}
$\sigma : \mathbb{R}^n \to \mathbb{R}$, bounded (i.e., $|\sigma (x)| \leq c \ \forall x \in \mathbb{R}^n $)

Why? $V(x) = \frac{1}{2}s(x)^2$
\begin{equation*}
\dot{V} = s(x)(L_fs(x) + L_gs(x)u + L_gs(x)\sigma (x)) = - s(x)sgn(s(x)) \hat{u} |L_gs(x)| + s(x)L_gs(x)\sigma (x) \leq - |s(x)| |L_gs(x)| (\hat{u} - c)
\end{equation*}
\begin{equation*}
u = - \frac{1}{L_gs(x)}(L_fs(x) + (\hat{u} + \beta (x) |L_gs(x)|) sgn(s(x)))
\end{equation*}
ensures robustness w.r.t. matched uncertainties s.t. $\sigma (x) \leq \beta (x) \ \forall x\in \mathbb{R}^n$

Example 2
\begin{Example}
\begin{equation*}
\begin{array}{l}
     \dot{x_1} = x_2 + x_1 sin(x_2)\\
     \dot{x_2} = \theta x_2^2 + x_1 + u
\end{array}
\end{equation*}

$|\theta| \leq 2 \leadsto |\theta x_2^2| \leq 2x_2^2 = \beta(x)$

\begin{equation*}
\dot{s} = \theta x_2^2 + x_1 +u +2x_1 +2x_1sinx_2
\end{equation*}
\begin{equation*}
u = -(x_1 +2x_1 +2x_1sinx_2 + \hat{u}sign(s(x)) + 2x_2^2sgn(s(x)))
\end{equation*}
$L_fs(x) = x_1 +2x_1 +2x_1sinx_2$

$\leadsto \dot{s} = - \hat{u}sgn(s(x)) + x_2^2(\theta - 2sgn(s(x))) \Rightarrow$ finite -time convergence to $S$.
\end{Example}

%TODO picture

Remedy: replace sign-function by saturated slope (continuous approximation)

can be extended to multi-input systems $u \in \mathbb{R}^m \to s: \mathbb{R}^n \to \mathbb{R}^m$

\subsection{Dissipativity}

%TODO picture

Dissipativity: Generalization of Lyapunov theory to systems $w$ inputs and outputs

\begin{equation}\label{input-output}
\begin{array}{lll}
     \dot{x} = f(x,u) & x(0) = x_0 & f: \mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R}^n \\
     y = h(x) & & h: \mathbb{R}^n \to \mathbb{R}^p
\end{array}
\end{equation}

Definition: 
\begin{itemize}
\item storage function $s: \mathbb{R}^n \to \mathbb{R}$, $x \to S(x)$ nonnegative (i.e., $s(x) \geq 0 \ \forall x \in \mathbb{R}^n$)
\item supply rate $s: \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$, $(u,y) \to s(u,y)$
\end{itemize}

Definition: System (\ref{input-output}) is dissipative w.r.t. the supply rate $s$ if there exists a storage function $S$ s.t. $\forall x_0 \in \mathbb{R}$, $\forall t \geq 0$, $\forall u : [0, t] \to \mathbb{R}^m$

\begin{equation*}
S(x(t)) \leq S(x_0)
 + \int_0^ts(u(\tau), y(\tau))d\tau
\end{equation*}  

First item - storage at time $t$, second item - initial storage,the last item - supply delivered over [0, $t$]

"dissipation inequality" (DIE)

Interpretation:
\begin{itemize}
\item "Dissipative systems dissipate storage/stored energy"
\item "No storage/energy can be created internally"
\item positive $s$ "supplied" energy/ storage
     
      negative $s$ "extracted" energy / storage
\end{itemize}

Remark: 
\begin{itemize}
\item If $S$ is differentiable, DIE is equivalent to $\dot{S}(x) \leq s(u,y) \ \forall u, x$
\item Dissipation (rate) is defined as $d(x,u) = s(u,h(x)) - \dot{S}(x) \geq 0$
\end{itemize}

Examples of dissipative systems:
\begin{center}
    \begin{tabular}{| l | l | l | l | l |}
    \hline
     & supply rate & input & output & storage function  \\ \hline
    electrical & $u \cdot i$ & voltage & current & energy storage in all capacitors and inductors\\ \hline
    mechanical & $F \cdot V$ & force & velocity & Hamiltonian = kinetic + potential energy \\ \hline
    thermo-dynamics & $Q + W$ & rate of hate & rate of work & internal energy \\
    \hline
    & $-\frac{a}{T}$ & & temperature & entropy \\
    \hline
    \end{tabular}
\end{center}

How do we computer storage functions?
\begin{itemize}
\item in general difficult (similar to computing Lyapunov functions)
\item characterization via optimization problem
\end{itemize}

Introduce "available storage"
\begin{equation*}
S_a(x) := sup_{u:[0,T] \to \mathbb{R}^m, T \geq 0, x(0) = 0} (- \int_0^Ts(u(\tau),y(\tau)))
\end{equation*}

the maximum of energy we can extract

\begin{Theorem}
System (\ref{input-output}) is dissipative w.r.t. the supply rate $s$ iff $S_a(x) < \infty$ for all $x \in \mathbb{R}^n$

Moreover, if $S_a(x) < \infty$ for all $x \in \mathbb{R}^n$, then $S_a$ is a storage function and $S(x) \geq S_a(x) \ \forall x \in \mathbb{R}^n$ for all storage functions $S$.

\begin{proof}
Sketch of proof. "$S_a(x) < \infty \Rightarrow$ dissipativity". $S_a(x) \geq 0 \ \forall x \in \mathbb{R}^n$ by definition (can take $T=0$)
\begin{equation*}
S_a(x) = sup_{u[0,T] \to \mathbb{R}^m, T \geq 0, x(0) = 0}- \int_0^Ts(u(\tau), y(\tau))d\tau \geq^* - \int_0^t s(u(\tau), y(\tau))d\tau + sup_{u[t,t+T] \to \mathbb{R}^m, T \geq 0, x(t) = x(t)} - \int_t^{t+T}s(u(\tau), y(\tau))d\tau
\end{equation*} 
the last item is $S_a(x(t))$, 
\begin{equation*}
\Rightarrow = S_a(x(t)) - \int_0^ts(u(\tau), y(\tau))d\tau
\end{equation*}
and this is DIE $\Rightarrow S_a$ is a storage function

Note for (*): "suboptimal" to first transfer system to $x(t)$ and then extract maximum energy starting of $x(t)$

"Dissip. $\Rightarrow S_a(x) < \infty$"

From DIE: $S(x_0) \geq S(x(T)) - \int_0^Ts(u(\tau), y(\tau))d\tau \geq - \int_0^T s(u(\tau),y(\tau))d\tau$

for all $x_0$, for all $T \geq 0$, all $u(\cdot) \Rightarrow S(x_0) \geq sup_{u:[0,T] \to \mathbb{R}^m, \ T \geq 0, \ x(0) = x_0} - \int_0^Ts(u(\tau),y(\tau))d\tau = S_a(x)$

$\Rightarrow S_a(x) < \infty \ \forall x \in \mathbb{R}^n$ and $S \geq S_a$ for all storage function $S$. 
\end{proof}
\end{Theorem}

Another special supply rate: "required supply"

\begin{equation*}
S_r(x) := inf_{u:[-T,0] \to \mathbb{R}^m, \ T \geq 0, \ x(-T) = x^*, \ x(0) = x} \int_T^0 s(u(\tau), y(\tau))d\tau
\end{equation*}

\begin{Theorem}
Assume that end state $x \in \mathbb{R}^n$ is readable from $x^*$. If system (\ref{input-output}) is dissipative w.r.t. the supply rate $s$, then for all storage functions $S$
\begin{equation*}
S(x) \leq S_r(x) + S(x^*) \ \forall \in \mathbb{R}^n
\end{equation*}
Furthermore, $S_r(x) + S(x^*)$ is a storage function.
\begin{proof}
Sketch of proof.

Consider $u:[-T,0] \to \mathbb{R}^n$ which transfers the system from $x^*$ to $x$
\begin{equation*}
S(x) - S(x^*) \leq[by DIE] inf_{u[-T,0] \to \mathbb{R}^n, \ T \geq 0, \ x(-T) = x^*, \ x(0) = x} \int_{-T}^0 s(u(\tau), y(\tau))d\tau = S_r(x)
\end{equation*}
\end{proof}
\end{Theorem}

Remark: Set of all storage functions is convex, i.e. , $\alpha S_1 + (1-\alpha) S_2$, $\alpha\in [0,1]$ is a storage function (for $S1, \ S2$ storage functions)

Dissipativity widely used in control theory

If system is dissipative with positive definite storage $S$ and if there exists a (continuous) $k: \mathbb{R}^n \to \mathbb{R}^n$ s.t. 
\begin{equation*}
s(k(x),h(x)) < 0, \ \forall x \neq 0
\end{equation*}
then $x=0$ is asymptotically stable under $u=k(x)$

Why? Take $S$ as Lyapunov function 
\begin{equation*}
\dot{S} \leq s(u,y) =^{u=k(x)} s(k(x),h(x)) < 0, \ \forall x \neq 0
\end{equation*}

$L_2$ - gain via supply rate 
\begin{equation*}
s(u,y) = \frac{1}{2} \gamma^2 \|u\|^2 - \frac{1}{2}\|y\|^2
\end{equation*}
$\leadsto $ from dissipation inequality

\begin{equation*}
\begin{split}
\frac{1}{2} \int_0^t \gamma^2 \|u(\tau)\|^2 + \|y(\tau)\|^2d\tau \geq S(x(t)) - S(x(0)) \geq -S(x(0)) \\
\Rightarrow \int_0^t \|y(\tau)\|^2d\tau \leq \gamma^2 \int_0^t \|u(\tau)\|^2d\tau + 2 S(x(0)) \\
\end{split}
\end{equation*}
$\Rightarrow$ system has $L_2$ - gain $\gamma$

Classify optional $l(x,u^{\leftarrow x})$ operating conditions $s(u,y) = l(x,u) - l(x^*,u^*)$ 

%TODO picture

\begin{Example}
\begin{equation*}
\dot{x} = u, \ y = x 
\end{equation*}
$S(x) = \frac{1}{2}x^2, \ \dot{S} = xu = uy \leadsto $ system is dissipative w.r.t. supply rate $s(u,y) = uy$.
\end{Example}

\begin{Example}
"part-Hamiltonian systems" 
\begin{equation*}
\dot{x} = [F(x) - R(x)] \triangledown H(x) + g(x)u
\end{equation*}
$y = y(x)^T\triangledown H(x)$, $H$ - Hamiltonian total stored energy in system

$F(x) = -F^T(x)$ internal interconnection structure (power conserving) $R(x) \geq 0$ dissipation structure

Take $S(x) = H(x)$
\begin{equation*}
\begin{split}
\dot{S}(x) = \triangledown H(x) \cdot [F(x) -R(x)]\triangledown H(x) + \triangledown H(x) \cdot g(x)u \\
= - \triangledown H(x) \cdot R(x) \triangledown H(x) + yu \leq yu 
\end{split}
\end{equation*}
as far as $- \triangledown H(x) \cdot R(x) \triangledown H(x) \leq 0 \Rightarrow$ dissipative w.r.t. $s(u,y) = u^Ty$   
\end{Example}

\subsection{Passivity}

\begin{equation}\label{passivity_system}
\begin{split}
\dot{x} = f(x,u), \ x \in \mathbb{R}^n, \ u \in \mathbb{R}^m \\
y = h(x), \ y \in \mathbb{R}^m
\end{split}
\end{equation}
(same number of inputs and outputs)

\begin{Definition}
System (\ref{passivity_system}) is passive if it is dissipative w.r.t. supply rate $s(u,y) = u^Ty$
\end{Definition}

Why "passive"? From circuit theory passive compared to "active" ones as diods or transistors

Examples: electrical, mechanical systems

Stabilization of passive systems

\begin{Definition}
System (\ref{passivity_system}) is zero-state observable (ZSO) if (for $u(t)=0$) $y(t)=0$ for all $t \geq 0 \Rightarrow x(t) = 0$ for all $t \geq 0$

"trivial solution $x(t) \equiv 0$ is observable from the output" 
\end{Definition}

Remark: can be related to zero-state detectability

\begin{Theorem}
Let system (\ref{passivity_system}) be 

i) passive in differentiable storage set

ii)ZSO

Then the feedback $u=-Py, \ P > 0$ renders the origin asymptotically stable
\begin{proof}
Sketch of proof 
From passivity
\begin{equation}\label{passivity_inequality}
\dot{S} \leq u^Ty = -y^TPy \leq 0
\end{equation}
\begin{equation*}
S(x(t)) - S(x(0)) \leq - \int_0^ty(\tau)^TPy(\tau)d\tau , \ \forall t \geq 0
\end{equation*}
$S(x(t)) \geq 0$
\begin{equation}\label{sx0-inequiality}
S(x_0) \geq \int_0^ty(\tau)^TPy(\tau)d\tau, \ \forall t \geq 0
\end{equation}
$y(\tau)^TPy(\tau) \geq 0$. Want to show $S(x_0) > 0$ for all $x_0 \neq 0$. By contradiction. Suppose $\exists \bar{x} \neq 0$ with $S(\bar{x}) = 0$.

From (\ref{sx0-inequiality}) $\Rightarrow y(\tau) = 0 \ \forall \tau \geq 0$

By ZSO $\Rightarrow x(\tau) = 0 \ \forall \tau \geq 0 \Rightarrow \bar{x} = 0$

$\Rightarrow S$ is positive definite. $\Rightarrow$ Lyapunov stability together with (\ref{passivity_inequality})

For convergence, use (\ref{passivity_inequality}) together with La Salle's invariance principle and ZSO 
\end{proof}  
\end{Theorem}

Advantage. We have (static) output feedback (no observer needed)

Passivity of interconnections
\begin{enumerate}
\item Parallel interconnections of two passive systems are passive 
%TODO picture

Take $S(x_1,x_2) = S_1(x_1) +S_2(x_2)$.
\begin{equation*}
\dot{S} \leq u_1^Ty_1 + u_2^Ty_2 = u^T(y_1+y_2) = u^Ty
\end{equation*}
\item Feedback interconnection of passive systems are passive

%TODO picture

Take $S(x_1+x_2) = S_1(x_1) + S_2(x_2)$
\begin{equation*}
S \leq u_1^Ty_1 + u_2^Ty_2 =^{x_1=u_2=y} y^T(u_1+y_2) = y^Tu
\end{equation*}
\end{enumerate}

Remark:
\begin{itemize}
\item does not work for serious interconnections
\item can construct possibly large networks of passive systems
\end{itemize}

Stability if feedback interconnections:

Main idea: "shortage" of passivity of $H_1$ can be compensated by nexcess of passivity of $H_2$

\begin{Theorem}
Consider feedback interconnection (2) with $u \equiv 0$. Assume that $H_1$ and $H_2$ are (i) ZSO and dissipative with differentiable $S_1, \ S_2$ w.r.t. the supply rates
\begin{equation}\label{passivity_interconnection}
S_i(u_i,y_i) = u_i^Ty_i - \rho_iy_i^Ty_i - \nu_iu_i^Tu_i, \ i=1,2, \ \rho,\nu \in \mathbb{R}
\end{equation}
Then the origin $(x_1,x_2) = (0,0)$ for interconnection is asymptotically stable if $\nu_1 + \rho_2 > 0$ and $\nu_2 + \rho_1 > 0$.
\begin{proof}
Take $S(x) = S_1(x_1)+S_2(x_2)$.
\begin{equation*}
\begin{split}
\dot{S}(x) \leq^{(\ref{passivity_interconnection})} u_1^Ty_1 - \rho_1 y_1^Ty_1 - \nu_1u_1^Tu_1 \\
+ u_2^Ty_2 - \rho_2y_2^Ty_2 - \nu_2u_2^Tu_2 \\
= - (\rho_1 + \nu_2)y_1^Ty_1 - (\rho_2 +\nu_1)y_2^Ty_2
\end{split}
\end{equation*}

$u_1^Ty_1$ and $u_2^Ty_2$ can be excluded as $u_1=y_2, \ u_2 = y_1$. 

$\Rightarrow$ can show as in previous theorem that $S$ is positive definite $Rightarrow$ Lyapunov stability

For using La Salle:
\begin{equation*}
\begin{split}
y_1 \equiv 0 \Rightarrow u_2 \equiv 0 \Rightarrow^{ZSO} x_2 \equiv 0 \\
y_2 \equiv 0 \Rightarrow u_1 \equiv 0 \Rightarrow^{ZSO} x_1 \equiv 0
\end{split}
\end{equation*}
\end{proof}
\end{Theorem}

%Lecture missed

For $p \to \infty$ set of all measurable and (essentially) bounded functions $L_{\infty}$, for continuous $\phi$ 
\begin{equation*}
\|\phi\|_{L_{\infty}} = \inf \{ c \in \mathbb{R} | \|\phi(t)\| \leq c a.e.\} = \sup_{t > 0} \| \phi(t)\|
\end{equation*}
%TODO picture

\begin{Example}
\begin{equation*}
\phi (t) = e^{- \alpha t}, \ \alpha > 0, \ p \in [1,\infty )
\end{equation*}
\begin{equation*}
\begin{split}
\|\phi \|_{L_p} = \sqrt{p}{\int_0^{\infty} \|e^{-\alpha t}\|^p dt} = \\
= \sqrt{p}{[-\frac{1}{2p}e^{-\alpha pt}]_0^{\infty}} > \sqrt{p}{\frac{1}{2p}} < \infty \\
\Rightarrow \phi \in L_p \ \forall p \in [1, \infty) \ p= \infty : \\
\sup_{t \geq 0} \phi (t) = \phi (0) = 1 \Rightarrow p \in L_{\infty}
\end{split}
\end{equation*}
\end{Example}

Special case $p = 2$ 

$L_2$ can be equipped with an inner product $\phi_1, \phi_2 \in L_2$, we write $<\phi_1, \phi_2>_{L_2} :=  \int_0^{\infty} \phi_1(t)^T\phi_2(t)dt$

symmetry $<\phi_1, \phi_2>_{L_2} = <\phi_2, \phi_1>_{L_2}$

(bi- )linearity 
\begin{equation*}
\begin{split}
<\alpha \phi_1, \phi_2>_{L_2} = \alpha <\phi_1, \phi_2>_{L_2} \ \alpha \in \mathbb{R} \\ 
<\phi_1 + \phi_2, \phi_3>_{L_2} = <\phi_1, \phi_3>_{L_2} + <\phi_2, \phi32>_{L_2}
\end{split}
\end{equation*}
$\phi_3 \in L_2$ 
positive definiteness: $<\phi_1, \phi_1>_{L_2} = 0$ iff $\phi_1 = 0$, $<\phi_1, \phi_1>_{L_2} > 0$ else.

$\Rightarrow (L_2, <\cdot, \cdot>_{L_2})$ is an inner product space

$\|\ \phi|_{L_2}^2 = < \phi, \phi>_{L_2}$ "induced norm". Particularly useful(Cauchy -Schwarz inequality) $|<\phi_1,\phi_2>_{L_2}| \leq \|\phi_1\|_{L_2}\|\phi_2\|_{L_2}$

Original motivation 

%TODO picture

\begin{Example}
\begin{equation*}
\dot{x} = x+u, \ y = x, \ x(0) = 0
\end{equation*}
$y(t) = \int_0^te^(t-\tau)u(t)d\tau$

Take $u(t) = \left\{
                \begin{array}{ll}
                  1, \ \ 0 \leq t \leq 1\\
                  0, \ \ t > 1
                \end{array}
              \right. $
              
Clearly, $u \in L_p$ for any $p \in [1,\infty)$. Let $t geq 1$: 
\begin{equation*}
\begin{split}
y(t) = \int_0^1 e^{(t-\tau)}d\tau = e^t\int_0^1e^{-\tau}d\tau \\
= e^t[-e^{-\tau}]^1_0 = e^t(1-e^{-1})
\end{split}
\end{equation*}
$\Rightarrow y \not\in L_p, \ p \in [1,\infty) $.$\Rightarrow $ even that $ u \in L_p$, the output neednot be an $L_p$ - signal.
\end{Example}

Taking $H: L_p \to L_p$ does (in general) not make sense? (would be excluded too many "relevant" systems)

Meaningful longer class: extended $L_p$ spaces

Introduce "truncation operator"
\begin{equation*}
\phi_T(t) = \left\{
                \begin{array}{ll}
                  \phi (t), \ \ 0 \leq t \leq T\\
                  0, \ \ t > T
                \end{array}
              \right. 
\end{equation*}

The extension $L^e_p$ of $L_p$ is defined as 
\begin{equation*}
L^e_p = \{ \phi: [0,\infty) \to \mathbb{R}^n | \forall T \geq 0 \ \phi_T \in L_p\}
\end{equation*}
%TODO picture

$L^e_p \setminus L_p$ are "unstable" signals

\begin{Example}
$\phi (t) = e^t $ ("unstable linear system")
\begin{equation*}
\begin{split}
\|\phi_T\|^0_{L_p} = \int_0^{\infty} |\phi_T(t)|^pdt = \int_0^T|\phi(t)|^pdt =  \\
= \int_0^Te^{pt}dt = \frac{1}{p}(e^{Tp} - 1) < \infty, \ \forall T \geq 0 \\
\Rightarrow \phi \in L_p^e 
\end{split}
\end{equation*}
\end{Example}

We consider systems 
\begin{equation*}
H: u \mapsto y, L_p^e \mapsto L_p^e
\end{equation*}
and define input-output stability as follows:
\begin{Definition}
$H$ is $L_p$-stable if there exists $\alpha \in K, \ \beta \geq 0$ s.t. 
\begin{equation*}
\|(H(u))_T\|_{L_p} \leq \alpha (\|u_T\|_{L_p}) + \beta
\end{equation*}
for all $u \in L^e_p$ and all $T \geq 0$. 

$H$ is finite-gain $L_p$ stable if there exist $\gamma, \ \beta \geq 0$ s.t. 
\begin{equation}\label{finite_gain}
\|(H(u))_T\|_{L_p} \leq \gamma \|u_T\|_{L_p} + \beta 
\end{equation}
for all $u \in L_p^e$ and $T \geq 0$. Then $\gamma_p(H) := \{ \inf \gamma | \exists \beta \geq 0 s.t. (\ref{finite_gain}) holds\}$ is $L_p$ - gain of $H$
\end{Definition}
\begin{Definition}
A map $H: L_p^e \mapsto L_p^e$ is causal if $(H(u))_T = (H(u_T))_T$ for all $u \in L_p^e$ and $T \geq 0$. 
\end{Definition}

Interpretation: $H$ is "nonanticipativity", outputs up to time $T$ cannot be influenced by inputs after time $T$.

Remark: if $H$ is defined by $u \mapsto y, \ y = h(x), \ \dot{x} = f(x,u)$ then it is causal.
\begin{itemize}
\item (\ref{finite_gain})
\begin{equation}\label{causal_formula}
\Rightarrow \|H(u)\|_{L_p} \leq \gamma \|u\|_{L_p} + \beta, \ \forall u \in L_p
\end{equation}
\item For causal systems, (\ref{causal_formula}) implies (\ref{finite_gain})
\item sometimes slightly different definitions of finite-gain $L_2$ stability
\begin{equation}\label{finite_gain_stability}
\|(H(u))_T\|^2_{L_2} \leq \bar{\gamma}^2 \|u_T\|^2_{L_2} + \beta, \ \forall u \in L_p^e, \ \forall T \geq 0
\end{equation}
One can show 
\begin{equation*}
\gamma_2(H) := \{ \inf \bar{\gamma} | \exists \beta \geq 0 \ s.t. \ (\ref{finite_gain_stability})\ holds \}
\end{equation*}
\end{itemize}

\subsection{Input-output stability of state-space systems}

\begin{Theorem}
Consider $\dot{x} = f(x,u), \ y = h(x,u)$. Suppose the system is ISS and there exist $\alpha_1, \alpha_2 \in K$ and $\eta \geq 0$ s.t. $\|L(x,u)\| \leq \alpha_1(\|x\|) + \alpha_2(\|u\|) + \eta$. Then for each $x_0 \in \mathbb{R}^n$, the system is $L_{\infty}$ - stable.
\begin{proof}
From ISS, $\exists \phi \in KL$ and $\alpha_3 \in K$ s.t. for all $t \geq 0$.
\begin{equation*}
\|x(t)\| \leq \phi(\|x_0\|, t) + \alpha_3(\sup_{0\leq \tau \leq t}\|u(\tau)\|)
\end{equation*}
Hence 
\begin{equation*}
\begin{split}
\|y(t)\| \leq \alpha_1(\phi (\|x_0\|, t) + \alpha_3(\sup_{ 0 \leq \tau 
\leq t}\|u(\tau)\|)) + \alpha_2(\|u(t)\|) + \eta \leq \\ 
[\alpha_1(a+b) \leq \alpha_1(2a)+\alpha_2(2b)] \leq \alpha_1(2\phi(\|x_0\|,t)) + \alpha_1(2 \alpha_3(\sup_{0 \leq \tau \leq t}\|u(\tau)\|))\\
+ \alpha_2(\|u(t)\|)+\eta \Rightarrow \|y_T\|_{L_{\infty}} \leq \gamma(\|u_T\|_{L_{\infty}}) + \beta \\
with\ \gamma = \alpha_2 \circ 2\alpha_3 + \alpha_2, \ \beta = \alpha_1(2\phi(\|x_0\|,0)) + \eta
\end{split}
\end{equation*}
\end{proof}
\end{Theorem}