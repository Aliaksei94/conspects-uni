\section{Exercises}

\subsection{Exercise 1}

Problem 1:
\begin{proof}
    For any $t \ge 0$, we have
    $$\frac{d}{dt}V(x(t)) = \frac{d}{dt}(V \circ x)(t) = \langle \nabla V(x(t)), \frac{d}{dt}x(t) \rangle = \langle \nabla V(x(t)),f(x(t)) \rangle = L_fV(x(t))$$
\end{proof}

Problem 2:
\begin{proof}
    \begin{Lemma}
        Given the assumptions in Problem 2, if there exists a solution $x: [ 0,+\infty ] \to R^n, t \to x(t)$, of $\dot x = f(x)$ s.t. $x(t) \in K$ for any $t \ge 0$, where $k \subset R^n$ is a compact with $O \in K$ (O - origin), then $x(t) \xrightarrow{t \to + \infty} 0.$
    \end{Lemma}
    
    Clearly, for any $c > 0, lev_{\le c}V$ is positive invariant w.r.t $\dot x = f(x)$. Given $c > 0$, let $x_0 \in lev_{\le c}V$, i.e., $V(x_0) \le c$. Then, for any $t \ge 0$
    $$V(x(t)) = V(x_0) + \int_0^t \frac{d}{dt}V(x(\tau))d\tau < V(x_0) \le c,$$
    i.e. $x(t) \in lev_{\le c}V$ for any $t \ge 0$. \\
    Then, for any $x_0 \in lev_{\le c}V$ there exists a solution $x: [ 0,+\infty ] \to R^n$ of $\dot x = f(x)$ s.t. $x(t) \in lev_{\le c}V$ for all $t \ge 0$.
    Clearly, $O \in lev_{\le c}V$. We conclude by using the above Lemma $(K = lev_{\le c}V)$.
\end{proof}

Problem 3:
\begin{proof}
    Let $r > 0$. By assumption, there exists $c > 0$ s.t. $\overline{B(0,r)} \subset lev_{\le c}V$. \\
    Since any bounded set $lev_{\le c}V$ is a subset of the region of attraction, and since the sublevel sets are arbitrary large, $R^n$ is also the region of attraction. \\
    A condition that ensures that for any $c > 0, lev_{\le c}V$ is bounded is $V(x) \xrightarrow{||x|| \to + \infty} + \infty$.
\end{proof}

Problem 4:
\begin{proof}
    Let $P:R^2 \to R^2$ be continuously differentiable. Consider
    $$m \dot v = -g \nabla P(q).$$
    Consider $x=(q,v), \dot q = v, \dot v = - \frac{g}{m} \nabla P(q)$. Let $H:R^2 \to R$ be defined by
    $$H(q,v) = \frac{1}{2}||v||^2+\frac{g}{m}P(q).$$
    We have
    $$\begin{pmatrix}
        \dot q \\
        \dot v
    \end{pmatrix}
    =
    \begin{pmatrix}
        \space & I \\
        -I & \space
    \end{pmatrix}
    \nabla H(q,v)$$
    Since $P$ is positive definite, then $H$ is positive definite. \\
    Then
    $$L_{\begin{pmatrix} \space & I \\ -I & \space \end{pmatrix} \nabla H}H(q,v) = \langle \nabla H(q,v), \begin{pmatrix} \space & I \\ -I & \space \end{pmatrix} \nabla H(q,v) \rangle = 0 \ \ \forall (q,v) \in R^2 \times R^2$$
    $\implies$ the origin is stable.
\end{proof}

Problem 5:
\begin{proof}
    For any $t \ge 0$, we have \\
    $\frac{d}{dt}V(t,x(t)) = \frac{d}{dt}(V \circ (id_R,x))(t) = [id_R: R \to R, t->t] = \langle \begin{pmatrix}
            \frac{\partial}{\partial t}V(t,x(t)) \\
            \frac{\partial}{\partial x}V(t,x(t))
            \end{pmatrix},
    \frac{d}{dt}(id_R(t),x(t)) \rangle = 
    \langle \begin{pmatrix}
            \frac{\partial}{\partial t}V(t,x(t)) \\
            \frac{\partial}{\partial x}V(t,x(t))
            \end{pmatrix},
            \begin{pmatrix}
            1 \\
            f(t,x(t))
            \end{pmatrix} = 
            \frac{\partial}{\partial t}V(t,x(t)) + \langle \frac{\partial}{\partial x}V(t,x(t)), f(t,x(t)) \rangle = L_{\begin{pmatrix} 1 \\ f \end{pmatrix}}V(x(t)).$
            
            $g(t,x(t)) :=   \begin{pmatrix}
                            1 \\
                            f(t,x(t))
                            \end{pmatrix}$
\end{proof}

Problem 6:
\begin{proof}
    Consider $\dot x = a \sin(\omega t), \ \ x(0)=x_0 \in R \ \ a, \omega >0.$ \\
    This is solved by $x(t) = - \frac{a}{\omega} \cos (\omega t) + \frac{a}{\omega} + x_0.$ \\
    % TODO Picture
    Clearly, $x$ is bounded on $[0, +\infty]$ since $x(t) \ge x_0$, and $x(t) \le x_0+2 \frac{a}{\omega}$ for any $t \ge 0$. \\
    Choose $\varepsilon = \frac{a}{\omega}$ and $t_0=0$. Then $\forall \delta > 0 \ \ \exists x_0 \in B(0, \delta)$, namely $x_0$, s.t. $\exists t \ge t_0$, namely $t=\frac{\pi}{\omega}$, with $x(t) \notin B(0, \varepsilon) \ \ (x(\frac{\pi}{\omega})=2\frac{a}{\omega} > \varepsilon).$
\end{proof}

Short notes: \\

Problem 7: \\
Take $V(t,x)=\frac{1}{2}x^2$.\\

Problem 8: \\
Take $V(t,x)=x_1^2+(1+e^{-2t})x_2^2.$


\subsection{Exercise 2}

Problem 1:
\begin{proof}
    a) Since $\alpha_1$ is continuous and strictly increasing:
    $$\forall x,y \in [0,\delta), x<y \ \ \alpha_1(x)<\alpha_1(y)$$
    $\implies \alpha_1$ is injective, i.e.
    $$\forall x,y \in [0, \delta), x \neq y \implies \alpha_1(x) \neq \alpha_1(y).$$
    Clearly, $\alpha_1:[0,\delta) \rightarrow \alpha_1([0,\delta))$ is surjective, i.e.
    $$\forall y \in \alpha_1([0,\delta)) \ \ \exists x \in [0,\delta): \ \ \alpha_1(x)=y$$
    Thus $\alpha_1$ is bijective.\\
    Define $\alpha_1^{-1}:[0,\alpha_1(\delta)) \rightarrow [0,\delta)$ by $\alpha_1^{-1}(\alpha_1(x))=x$.
    
    b) From a) we have $\alpha_3^{-1} \in K$. Since $\alpha_3 \in K_{\infty}, \alpha_3{-1}$ is defined om $[0,+\infty)$ and $\alpha_3^{-1}(r) \xrightarrow[]{r \rightarrow \infty}\infty$
    
    c) Let $\alpha=\alpha_1 \circ \alpha_2$. Then we have $\alpha(0)=\alpha_1(\alpha_2(0))=0$ and $\alpha(r)>0$ whenever $r>0$. Moreover, for any $x,y$:
    $$x<y \implies \alpha_2(x) < \alpha_2(y) \implies \alpha(x)=\alpha_1(\alpha_2(x))<\alpha_1(\alpha_2(y))=\alpha(y)$$
    It is continuous (as composition of continuous functions).
    
    d) From c) we have $\alpha:=\alpha_3 \circ \alpha_4 \in K, \alpha$ is defined on $[0,+\infty)$ since $\alpha_3, \alpha_4 \in K_{\infty}$ and
    $$r \rightarrow +\infty \implies \alpha_4(r) \rightarrow +\infty \implies \alpha(r) \rightarrow +\infty$$
    
    e) For each $s, r \mapsto \beta(\alpha_2(r),s)$ is of class $K$.\\
    Thus $r \mapsto \alpha_1(\beta(\alpha_2(r),s)) \in K$.\\
    For each $r, s \mapsto \beta(\alpha_2(r),s)$ decreases.\\ 
    Hence, $s \mapsto \alpha_1(\beta(\alpha_2(r),s))$ decreases.\\
    Moreover,
    $$\alpha_1(\beta(\alpha_2(r),s)) \xrightarrow{s \rightarrow +\infty} 0$$
\end{proof}

Problem 3:
\begin{proof}
    For $u=0$ the origin is UGAS. Consider $V:[0,+\infty) \times R \rightarrow R, \ \ (t,x) \mapsto \frac{1}{2}x^2$. \\
    We have
    $$\frac{\partial}{\partial t}V(t,x) + \frac{\partial}{\partial x}V(t,x)f(t,x,u) = (\sin(t)-2)x^2+xu \le -x^2+|x||u| = -(1-\theta)x^2-\theta x^2+|x||u|, \ \ \theta \in (0,1)$$
    Hence, whenever $|x| \ge \frac{|u|}{\theta}$, the system is ISS with $\gamma=\frac{r}{\theta}$.
\end{proof}

Problem 4:
\begin{proof}
    \begin{equation} \label{ex:2:4:a}
        \dot x = -x + (x^2+1)d
    \end{equation}
        \begin{equation} \label{ex:2:4:b}
        \dot x = -2x -x^3 + (x^2+1)d
    \end{equation}
    
    System (\ref{ex:2:4:a}): Clearly, the system is 0-GAS. However, for $d=1$ and $x>1$ we have $x^2+1>x$.
    $$f(x,1) = -x+(x^2+1)>0$$
    and thus $\dot x>0$. Hence, if $x(0)=x_0>1$, the solution diverges (in finite time).\\
    $\implies$ System (\ref{ex:2:4:a}) isn't ISS.
    
    System (\ref{ex:2:4:b}): It is 0-GAS. Moreover, for any finite $d$ there exists a "large" $x$ s.t.
    $$2x+x^3>(x^2+1)d$$
    $$\implies f(x,d) = -2x-x^3+(x^2+1)d<0$$
    and $\dot x<0 \implies$ System \ref{ex:2:4:b} is ISS.\\
    Consider $V:R \rightarrow R, x \mapsto \frac{1}{2}x^2$ s.t
    $$V'(x)f(x,d)=-2x^2-x^4+x(x^2+1)d \le -x^2-x^2(x^2+1)+(x^2+1)|x||d|$$
    Hence, whenever $|x| \ge |d|$,
    $$V'(x)f(x,d) \le -x^2$$
    s.t. system (\ref{ex:2:4:b}) is ISS with $\gamma (r) = r$.
    \end{proof}
    
    Problem 5:
    \begin{proof}
        $$\langle \nabla V(x),-\nabla V(x)+\delta u\rangle \le -||\nabla V(x)||^2+|\langle \nabla V(x), \delta u \rangle| \le [YI] \le -||\nabla V(x)||^2+\frac{1}{2}||\nabla V(x)||^2+\frac{\delta^2}{2}||u||^2$$
        
        Young's inequality: \\
        $$\forall x,y: \ \ |\langle x,y \rangle| \le \varepsilon \frac{||x||^p}{p}+\frac{||y||^q}{\varepsilon q}, \ \ p,q>1, \frac{1}{p}+\frac{1}{q}=1, \varepsilon>0$$
        
        Hence, whenever $||x||>\frac{\delta}{\sqrt{c}}||u||, t \mapsto ||x(t)||$ is decreasing. \\
        Moreover whenever $||x|| \ge \frac{\delta}{\sqrt{c\theta}}||u||, \theta \in (0,1)$, we have $\langle \nabla V(x),-\nabla V(x)+\delta u\rangle \le -\frac{c}{2}(1-\theta)||x||^2 \implies$ ISS. 
    \end{proof}

\subsection{Exercise 3}

Motivation: Lyapunov Theory

\begin{equation*}
\dot{x} = f(x,u)
\end{equation*}
$f:\mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R}^n$

\begin{Definition}
(CLF) A function $V: \mathbb{R}^n \to \mathbb{R}$ is a CLF if it is continuous differentiable, positive definite, radially unbounded and $ \forall x \neq 0 \ \inf_{u}< \triangledown V(x), f(x,u) > < 0$ 
\end{Definition}

In order to find CLFs, we restrict our analysis to input -affine systems
\begin{equation*}
\dot{x} = f(x) + G(x)u
\end{equation*}
where $f: \mathbb{R}^n \to \mathbb{R}^n, \ G: \mathbb{R}^n \to \mathbb{R}^{n \times m}$

Proposition: A continuous, differentiable, positive definite and radially unbounded. $V: \mathbb{R}^n \to \mathbb{R}$ is a CLF iff 
\begin{equation*}
\forall x \neq 0 \ L_GV(x) = 0 \Rightarrow L_fV(x) < 0
\end{equation*}

Image to be inserted

Problem 1

Consider $\dot{x} = cos(x) + (1+e^x)u$ where $f(x) = cos(x)$- drift and $g(x) = 1+e^x$

Let $V: \mathbb{R} \to \mathbb{R}, \ x \mapsto \frac{1}{2}x^2$. Clearly, continuous differentiable, positive definite and radially unbounded. Moreover, for any nonzero $x$, we have $L_GV(x) \neq 0$. 

Thus, for any $x \neq 0$, there exists a control that readers $<\triangledown V(x), f(x) + g(x)u>$ negative. 
Givn this CLF, there exists a state feedback $u = u(x)$, e.g. 
\begin{equation*}
u(x) = - \frac{kx+cos(x)}{1+e^x}, \ k > 0
\end{equation*}

Problem

Consider 
\begin{equation*}
\dot{x_1} = -x_1^3 + x_2e^{x_1}cos(x_2)
\end{equation*}  
\begin{equation*}
\dot{x_2} = x_1^5sin(x_2) + u
\end{equation*}

Take $V: \mathbb{R}^2 \to \mathbb{R}, \ (x_1, x_2) \mapsto \frac{1}{2}(x_1^2 + x_2^2)$

For any $x \neq 0$, we have 
\begin{equation*}
\inf_{u \in \mathbb{R}}(L_fV(x) + L_GV(x)u) = 
\left \{ 
\begin{tabular}{cc} 
$L_fV(x), \ $ & $if\ L_GV(x) = 0$ \\ 
$- \infty$ & $else$ 
\end{tabular} 
\right.
\end{equation*}

In particular,
\begin{equation*}
L_fV(x) = \dots = x_1(-x_1^3 + x_2e^x_1 cos(x_2)) + x_2x_1^5sin(x_2)
\end{equation*}
\begin{equation*}
L_GV(x) = \dots = x_2
\end{equation*}

However, 
\begin{equation*}
L_fV(x)|_{x_2 = 0} = -x_1^4 < 0 \ \forall x_1 \neq 0
\end{equation*}

Image to be inserted

Concluding that $V$ is a CLF.

Problem 2:

$\dot{x} = Ax + Bu$, input defined system where $(A,B)$ is stabilizable, there exists $K \in \mathbb{R}^{m \times n}$ s.t. $A+BK$ is Hurwitz (cf. KRT).The latter is equivalent to the existance $P = P^T > 0$ s.t. $P(A+BK) + (A+BK)^TP < 0$ (cf. Khalil theorem 4,6)

Let $V: \mathbb{R}^n \to \mathbb{R}, x \mapsto <x, Px>$. Moreover, $\forall x \neq 0 \exists u = Kx$ s.t. $<\triangledown V(x), Ax+Bu> < 0$, since 
\begin{equation*}
<\triangledown V(x), Ax+Bu> =^{u = Kx} <x, (P(A+BK)+ (A+BK)^TP)x> < 0
\end{equation*} 

In addition,
\begin{equation*}
\forall \epsilon > 0 \exists \delta = \frac{\epsilon}{\|K\| } > 0 \ \forall x \neq 0, \ \|x\| < \delta \ \exists u = Kx \ \|u\| < \epsilon 
\end{equation*}
s.t. $L_fV(x) + L_GV(x)u < 0$ since $\|u\| = \|Kx\| \leq \|K\|\|x\| < \|K\|\delta = \epsilon$

Problem 3

Let $P: \mathbb{R}^2 \to \mathbb{R}$ be continuous, differentiable consider 
\begin{equation*}
m\dot{v}  = - g \triangledown P(q) + F, \ m,g >0
\end{equation*} 
a) Hamiltonian form. Let $x:=(q,v)$. Then $\dot{x} = (-\frac{g}{m}\triangledown P(q) + \frac{1}{m}F)= \begin{bmatrix}
 & I \\
 -I & 
\end{bmatrix}\begin{bmatrix}
 \frac{g}{m}\triangledown P(q) \\
 v 
\end{bmatrix} + \begin{bmatrix}
  \\
 \frac{1}{m}I
\end{bmatrix}F = \begin{bmatrix}
 & I \\
 -I & 
\end{bmatrix} \triangledown H(x) + G(x)$ given $H(x) = \frac{1}{2}\|\nu\|^2 + \frac{g}{m}P(q)$

b) "CLF". Take $H$ as a CLF candidate. Then, for any $x$ 
\begin{equation*}
\begin{split}
<\triangledown H(x), \begin{bmatrix}
 & I \\
 -I & 
\end{bmatrix} \triangledown H(x) + G(x)F> =& <\triangledown H(x), \begin{bmatrix}
 & I \\
 -I & 
\end{bmatrix} \triangledown H(x)> + <\triangledown H(x), G(x)F> = \\
& [<\triangledown H(x), \begin{bmatrix}
 & I \\
 -I & 
\end{bmatrix} \triangledown H(x)> = L_fH(x) = 0] = \frac{1}{m} <v, F>
\end{split}
\end{equation*}

Strictly speaking, $H$ is no CLF, but it reveals how to choose $F$ s.t. the origin is GAS.

For any point $x$ for which there exists no control $F$ s.t. $<\triangledown H(x), \begin{bmatrix}
 & I \\
 -I & 
\end{bmatrix} \triangledown H(x) + G(x)F> < 0$

Choose $F = 0$. Why? Using the Krasovsky-Lasallle inv. principle, we conclude that the origin is GAS, since any solution in $\{ x| \dot{H}(x) = 0 \}$ verifies $v(t) \equiv 0$, implying $\dot{v}(t) \equiv 0$ s.t. 
\begin{equation*}
0 = - \frac{g}{m} \triangledown P(q(t)) + \frac{1}{m} P(t)
\end{equation*}
The last part equals 0.  Since $F = 0$ (by choice) and $\triangledown P(q) = 0$ iff $q = 0$ we conclude that $\dot{H}(x) = 0$ can only be "maintained" at the origin.

Problem 4

Consider 

\begin{equation*}
\dot{x_1} = x_2
\end{equation*}
\begin{equation*}
\dot{x_2} = - ux_2 + u^3
\end{equation*}

show that $V(x) = \frac{1}{2} x_1^2 + \frac{1}{2}(x_1 +x_2)^2$ is CLF and let $V: \mathbb{R}^n \to \mathbb{R}$ be defined by

\begin{equation*}
\ddot{x} + u\dot{x} - u^3 = 0
\end{equation*}

For any $x$ and $u$, we have $<\triangledown V(x), f(x,u)> = \dots = x_1(2x_2 -ux_2 + u^3) + x_2(x_2 - ux_2 + u^3) = x_1h_1 + x_2h_2$

Image to be inserted

Hence if $u < 0$ and $-u$ "large", then we can render $<\triangledown V(x), f(x,u)> < 0$.

   
    \subsection{Exercise 4}
    
    Consider
    \begin{equation} \label{ex:4:theory:1}
    \left\{\begin{array}{ll}
        \dot x_1 = f_1(x_1)+g_1(x_1)x_2 \\
        \dot x_2 = f_2(x_1)+g_2(x_1,x_2)u
    \end{array} \right.
    \end{equation}
    Using the "preliminary control"
    \begin{equation} \label{ex:4:theory:2}
    \left\{\begin{array}{ll}
        \dot x_1 = f_1(x_1)+g_1(x_1)x_2 \\
        \dot x_2 = \check u
    \end{array} \right.
    \end{equation}
    $$u=\frac{1}{g_2(x_1,x_2)}(\check u - f_2(x_1,x_2))$$
    Idea: Look at the upper(-most) system only and consider $x_2$ as a "virtual control". \\
    
    Assumptions: Suppose \\
    \begin{itemize}
        \item $\exists$ CLF $V_1$;
        \item $\exists$ (smooth) feedback $\alpha_1$ s.t. $L_{f_1+g_1\alpha_1}V_1 < 0$.
    \end{itemize}
    Now, add and subtract $g_1\alpha_1$ in \ref{ex:4:theory:2} s.t.
    \begin{equation} \label{ex:4:theory:3}
    \left\{\begin{array}{ll}
        \dot x_1 = f_1(x_1)+g_1(x_1)\alpha_1(x_1)+g_1(x_1)(x_2-\alpha_1(x_1)) \\
        \dot x_2 = \check u
    \end{array} \right.
    \end{equation}
    Next, introduce $(e_1,e_2):=(x_1-0,x_2-\alpha_1(x_1))$ s.t.
     \begin{equation} \label{ex:4:theory:4}
    \left\{\begin{array}{ll}
        \dot e_1 = f_1(e_1)+g_1(e_1)\alpha_1(e_1)+g_1(e_1)e_2 \\
        \dot e_2 = \check u - \dot \alpha_1(e_1)
    \end{array} \right.
    \end{equation}
    
    Problem 1:
    $$\begin{pmatrix}
        \dot x_1 \\
        \dot x_2
    \end{pmatrix}
    =
    \begin{pmatrix}
        1 & 1 \\
        0 & 0
    \end{pmatrix}
    \begin{pmatrix}
        x_1 \\
        x_2
    \end{pmatrix} + 
    \begin{pmatrix}
        0 \\
        1
    \end{pmatrix} u$$
    
    \begin{proof}
        \begin{enumerate}
            \item Choose "virtual control":\\
            $$x_2 = -(k+1)x_1 =: \alpha_1(x_1), \ \ k>0$$
            The origin of $\dot x_1 = -kx_1$ is GAS. \\
            (Take $V_1: R \rightarrow R, \ \ x_1 \mapsto \frac{1}{2}x_1^2$ s.t. $\dot V_1(x_1) = -kx_1^2 < 0$ for all $x_1 \neq 0$)
            \item Error coordinates:\\
            Let $(e_1,e_2):=(x_1-0,x_2-\alpha_1(x_1))$ s.t.
            $$\dot e_1 = -ke_1+e_2$$
            $$\dot e_2 = u+(k+1)(-ke_1+e_2)$$
            \item "Composite CLF":\\
            Define $V:R \times R \rightarrow R, \ \ (e_1,e_2) \mapsto V_1(e_1)+\frac{1}{2}e_2^2$ s.t.
            $$\dot V (e_1,e_2) = -ke_1^2 + e_2(u+(k+1)(-ke_1+e_2)+e_1)$$
            \item Choose control:\\
            Let $u = -e_1-(k+1)(e_2-ke_1)-ke_2$ \\
            s.t. $\dot V(e_1,e_2) = -ke_1^2-ke_2^2 < 0$ for all $(e_1,e_2) \neq (0,0)$
        \end{enumerate} 
        
        Remark: The closed-loop system reads:
        $$\begin{pmatrix}
        \dot e_1 \\
        \dot e_2
        \end{pmatrix}
        =
        \begin{pmatrix}
            -k & 1 \\
            -1 & -k
        \end{pmatrix}
        \begin{pmatrix}
            e_1 \\
            e_2
        \end{pmatrix}$$
    \end{proof}
    
    Problem 2:
    $$\dot x_1 = x_1(x_2-k), \ \ k>0$$
    $$\dot x_2 = u$$
    \begin{proof}
        \begin{enumerate}
            \item $x_2 = 0 =: \alpha_1(x_1)$ \\
            The origin of $\dot x_1 = -kx_1$ is GAS ($V_1(x_1) = \frac{1}{2}x_1^2$)
            \item $(e_1,e_2) := (x_1,x_2)$ s.t.
            $$\dot e_1 = e_1(e_2-k)$$
            $$\dot e_2 = u$$
            \item $V(e_1,e_2) = V_1(e_1)+\frac{1}{2}e_2^2$ s.t. \\
            $$\dot V(e_1,e_2) = -ke_1^2 + e_2(e_1^2+u)$$
            \item $u=-e_1^2-ke_2$
        \end{enumerate}
    \end{proof}
    
    Problem 3:
    $$\dot x_1 = x_1(x_2-k)$$
    $$\dot x_2 = x_2(x_3-k)-x_1^2$$
    $$\dot x_3 = u$$
    \begin{proof}
        \begin{enumerate}
            \item From problem 2: \\
            $\dot x_2 = x_2(x_3-k)-x_1^2 = - x_1^2-kx_2 = u$ in Problem 2.\\
            The origin of 
            $$\dot x_1 = x_1(x_2-k)$$
            $$\dot x_2 = x_2(x_3-k)-x_1^2$$
            is GAS. \\
            And this is true for $x_3 = 0 =: \alpha_2(x_1,x_2)$.
            \item $(e_1,e_2,e_3) := (x_1-0, x_2-\alpha_1(x_1), x_3-\alpha_2(x_1,x_2))$ s.t.
            $$\dot e_1 = e_1(e_2-k)$$
            $$\dot e_2 = e_2(e_3-k)-e_1^2$$
            $$\dot e_3 = u$$
            \item $V(e_1,e_2,e_3) = V_1(e_1)+\frac{1}{2}e_2^2+\frac{1}{2}e_3^2$ s.t. \\
            \item $u=-e_2^2-ke_3$
        \end{enumerate}
    \end{proof}
    
    Problem 4:
    $$\dot x_1 = x_1(x_2-k)$$
    $$\dot x_2 = x_2(x_3-k)-x_1^2$$
    $$\dot x_3 = x_3(x_4-k)-x_2^2$$
    $$\dot x_4 = u$$
    \begin{proof}
        \begin{enumerate}
            \item Is GAS for
            $$x_3(x_4-k)-x_2^2 = - x_2^2-kx_3$$
            which is attained for $x_4 = 0 =: \alpha_3(x_1,x_2,x_3)$.
            \item
            $$\dot e_1 = e_1(e_2-k)$$
            $$\dot e_2 = e_2(e_3-k)-e_1^2$$
            $$\dot e_3 = e_3(e_4-k)-e_2^2$$
            $$\dot e_4 = u$$
            \dots
            \item $u=-e_3^2-ke_4$
        \end{enumerate}
    \end{proof}
    
    Problem 5:
    $$\dot x_1 = x_1(x_2-k)$$
    $$\dot x_2 = x_2(x_3-k)-x_1^2$$
    $$\dots$$
    $$\dot x_i = x_i(x_{i+1}-k)-x_{i-1}^2$$
    $$\dots$$
    $$\dot x_n = u$$
    \begin{proof}
        We will always have $u = -e_{n-1}^2-ke_n$. \\
        Let $V: R \times \dots \times R \rightarrow R, \ \ (e_1, \dots e_n) \mapsto \sum_{i=1}^n V_i(e_i)$, where $V_i(e_i) = \frac{1}{2}e_i^2, \ \ i=2, \dots n$.\\
        We have $\dot V(e_1, \dots e_n) = L_{f_1+g_1\alpha_1}V_1(e_1)-k\sum_{i=2}^{n-1}e_i^2 + e_nu + e_{n-1}g_{n-1}(x_1, \dots x_{n-1})e_n - e_n \dot \alpha_{n-1}(x_1, \dots x_{n-1}).$\\
        We observe that for $\alpha_i$ being zero, the inequality
        $$e_{n-1}g_{n-1}(x_1, \dots x_{n-1})e_n - e_n \dot \alpha_{n-1} (x_1, \dots x_{n-1}) + e_nu  0$$
        hence $e_{n-1}^2e_n + e_nu < 0$ for non-zero $e$.\\
        It is solved by $u = -e_{n-1}^2 - ke_n, \ \ k>0$.
    \end{proof}
    
    \subsection{Exercise 5}
    
    Consider the SISO system
    $$\dot x = f(x)+g(x)(u+\sigma(x))$$
    $$y=s(x)$$
    $f,g: R^n \rightarrow R^n, \ \ \sigma: R^n \rightarrow R$ and bounded, \ \ $s: R^n \rightarrow R$\\
    
    Design steps for SMC:\\
    \begin{enumerate}
        \item If no output is provided, design a sliding surface $S:=\{x \in R^n|s(x)=0\}$ s.t.
        \begin{enumerate}[label=(\alph*)]
            \item the system has rel. degree one;
            \item for $y(t) \equiv 0$, all solutions converge to the origin ("zero dynamics" have GAS origin)
        \end{enumerate}
        \item Choose a control s.t. the sliding surface is reached (in finite time), e.g. \\
        $$v(x) = - \frac{1}{L_gs(x)}(L_fs(x)+ \hat u \cdot sgn(s(x))), \ \ \hat u > 0$$
    \end{enumerate}
    
    Problem 1:
    $$\dot x_1 = (x_2-x_1)x_1^2$$
    $$\dot x_2 = x_2 + u$$
    Sliding surface $S, \ \ s:R^2 \rightarrow R, \ \ (x_1,x_2) \mapsto x_2$
    \begin{proof}
        \begin{enumerate}[label=(\alph*)]
            \item For the given S, we have $L_gs(x)=1$ for any $x \in R^2$.\\
            Moreover, from\\
            $$\dot s(x) = L_fs(x)+L_gs(x)u$$
            (we want $= 0$) we have that for
            $$u=-\frac{L_fs(x)}{L_gs(x)}=-x_2$$
            the "dynamics on $S$" (i.e. $x_2=0$) reduced to
            $$\dot \eta = - \eta^3$$
            whose origin is GAS.
            \item Consider
            $$u = - \frac{1}{L_gs(x)}(L_fs(x)+ \hat u \cdot sgn(s(x))) = -x_2 - \hat u \cdot sgn(x_2), \ \ \hat u > 0$$
            such that $x(t)$ "tends to $S$" in finite time (phase 1). Moreover, "on S", $x(t)$ converges to the origin $t \rightarrow +\infty$ (phase 2).
        \end{enumerate}
    \end{proof}
    
    Remark:
    Given a system in regular form
    $$x = (\eta, \xi)^T$$
    $$\dot \eta = f_1(\eta, \xi)$$
    $$\dot \xi = f_2(\eta, \xi) + g_2(\eta, \xi)u$$
    choose $s(x) = \xi - \Phi(\eta)$, s.t. $\Phi$ as. stabilizes $\dot \eta = f_1(\eta, \Phi(\eta))$.
    
    Problem 2:
    $$\dot x_1 = -x_1\cos{x_2} + x_1x_2$$
    $$\dot x_2 = x_1\cos{x_1} + \sigma(x) + u$$
    \begin{proof}
        \begin{enumerate}[label=(\alph*)]
        \item (For the design of sliding surface pretend that uncertainty $\sigma(x)=0$)\\
        Let $S:=\{x \in R^2|s(x)=0\}$ be def. by $s:R^2 \rightarrow R, \ \ (x_1,x_2) \mapsto x_2(-\Phi(x_1) = 0)$.
        We have $L_gs(x)=1$ for all $x \in R^2$.\\
        From
        $$\dot s(x) = L_fs(x)+L_gs(x)u$$
        (we want $= 0$) s.t. for $u=-\frac{L_fs(x)}{L_gs(x)}(=-x_1\cos{x_1})$ the "dynamics on $S$" (i.e. $x_2=0$) reads
        $$\dot \eta = -\eta$$
        whose origin is GAS.
        \item Take
        $$u = - \frac{1}{L_gs(x)}(L_fs(x)+ (\hat u + \beta(x)|L_gs(x)|) \cdot sgn(s(x))) (= -x_1\cos{x_1}-(\hat u + (x_1^2+x_2^2)) \cdot sgn(x_2)), \ \ \hat u > 0$$
        Consider the Lyapunov(-like) function $V(x)=\frac{1}{2}s(x)^2$ s.t.
        $$\dot V(x) = s(x)(L_fs(x)+L_gs(x)(u+\sigma(x)))$$
        Choosing $u$ as above\\
        $\dot V(x) = s(x)(-(\hat u + \beta(x)|L_gs(x)|) \cdot sgn(s(x)) + \sigma(x)L_gs(x)) \le -(\hat u + \beta(x)|L_gs(x)|)|s(x)| + |\sigma(x)||L_gs(x)||s(x)|\le - \hat u |s(x)| < 0$ for $s(x) \neq 0$
        \end{enumerate}    
    \end{proof}
    
    Problem 3:
    $$\dot x_1 = x_2$$
    $$\dot x_2 = -x_1^3+\sigma(x)+u$$
    $s(x)=x_2+x_1, \ \ u = -x_2+x_1^3-2 \cdot sgn(s(x))$
    \begin{proof}
        \begin{enumerate}[label=(\alph*)]
            \item Given $S$, we have $L_gs(x) = 1$ for all $x \in R^2$. The "dynamics on $S$" (i.e. $x_1+x_2=0$) reads
            $$\dot \eta_1 = -\eta_1$$
            $$\dot \eta_2 = -\eta_2$$
            whose origin is GAS.
            \item Take $V(x) = \frac{1}{2}s(x)^2$ s.t.\\
            $\dot V(x) = s(x)(L_fs(x)+L_gs(x)(u+\sigma(x))) \le -\hat u |L_gs(x)||s(x)|+|\sigma(x)||L_gs(x)||s(x)| \le [|\sigma(x)| \le c] \le -(\hat u - c)|L_gs(x)||s(x)|$.\\
            Hence, for $c < \hat u = 2$ there exists $\varepsilon > 0$ s.t. $\dot V(x) \le - \varepsilon|s(x)| < 0$ for $s(x) \neq 0$
        \end{enumerate}
    \end{proof}
    
    \subsection{Exercise 6}
    
    Problem 1:
    $$\dot x = xu(x^2+u)$$
    $$y = h(x)$$
    $s:R \times R \rightarrow R, \ \ (u,y) \mapsto uy^2+u^2y$ \\
    $S:R \rightarrow R, \ \ x\mapsto \frac{x^2}{2}$
    \begin{proof}
        Clearly, S is non-negative. Moreover:\\
        $\dot S(x) = x^2u(x^2+u)=x^4u+x^2u^2=[h(x)=x^2]=s(u,x^2)$\\
        for all $x,u \in R$ with $h:R \rightarrow R, x \mapsto x^2$.
    \end{proof}
    
    Problem 2:
    $$\dot x = u, \ \ x(0)=x_0$$
    $$y=x$$
    $s: R^n \times R^n \rightarrow R, \ \ (u,y) \mapsto <u,y>$
    \begin{proof}
        For any $x_0 \in R^n$, we have
        $$S_a(x_0)=\sup_{u:[0,t] \rightarrow R^n, \ t \ge 0, \ x(0)=x_0} (- \int_0^t <u(\tau),y(\tau)> d\tau) =$$
        $$ =\sup_{-//-}(-\frac{1}{2}\int_0^t \frac{d}{d\tau}||x(\tau)||^2d\tau) = \sup_{-//-}(-\frac{1}{2}||x(t)||^2+\frac{1}{2}||x(0)||^2) \le \frac{1}{2}||x_0||^2$$ 
        $\implies$ av. storage is finite $\implies$ system is dissipative.
    Moreover, we have for any $x_0 \in R^n,$
    $$S_r(x_0) = \inf_{u:[-t,0] \rightarrow R^n, \ t \ge 0, \ x(-t) = 0, \ x(0) = x_0} \int_{-t}^0 <u(\tau),y(\tau)> d\tau = \inf_{-//-} (\frac{1}{2}||x_0||^2-\frac{1}{2}||x(-t)||^2) = \frac{1}{2}||x_0||^2$$
    ($S_a=S_r \implies$this is a unique stor. func.)\\
    Hence the (lossless) system is reachable (from 0 to any $x_0$).
    \end{proof}
    
    Problem 3:
    \begin{proof}
        Consider the Lyapunov func. cand. $V(x) = S_1(x_1) + S_2(x_2)$ s.t. \\
        $\dot V (x) \le s_1(u_1,y_1) + s_2(u_2,y_2) = s_1(u_1,y_1) + s_2(y_1,-u_1) = 0 \implies$ origin is stable.\\
    \end{proof}
    
    Remark: the above problem captures many stability results (in the frequency domain). Particular choices of supply rates are:
    \begin{itemize}
        \item $s_i(u_i,y_i) = ||u_i||^2-||y_i||^2, i=1,2$ (small-gain theorem);
        \item $s_i(u_i,y_i) = <u_i,y_i>, i=1,2$ (positive operator theorem);
        \item $s_1(u_1,y_1) = <u_1+ay_1, u_1+by_1>$\\
        $s_2(u_2,y_2) = -ab<u_2-\frac{1}{a}y_2, u_2-\frac{1}{b}y_2>$ (conic operator theorem).
    \end{itemize}
    
    Problem 4:
    $$\dot x = f(x)+G(x)u$$
    $$y=h(x)$$
    $s: R^m \times R^m \rightarrow R, \ \ (u,y) \mapsto ||u||^2-||y||^2$
    \begin{proof}
        Take $V=S$ s.t.
        $$\dot V(x) \le ||u||^2-||h(x)||^2, \ \forall x \in R^n, \ \forall u \in R^m$$
        Then the (continuous) state feedback $u = \gamma h(x)$ for some $|\gamma|^2 < 1$, s.t.
        $$\dot V(x) \le (|\gamma|^2-1)||h(x)||^2 < 0, \ \forall x \neq 0$$
    \end{proof}
    
    Problem 5:
    \begin{proof}
        Take $S(x) = <x,P_x>$ s.t. 
        $$\dot S(x) = <x, (PA+A^TP)x>+2<x,PBu>$$
        Add and subtract $\gamma^2||u||^2$ and $\frac{1}{\gamma^2}||B^TPx||^2$.
        $$\dot S(x) = <x, (PA+A^TP+\frac{1}{\gamma^2}PBB^TP)x>+\gamma^2||u||^2-\gamma^2||u -\frac{1}{\gamma^2}B^TPx||^2$$
        Add and subtract $||y||^2$.
        $$\dot S(x) = <x, (PA+A^TP+\frac{1}{\gamma^2}PBB^TP+C^TC)x>+\gamma^2||u||^2-||y||^2-\gamma^2||u-\frac{1}{\gamma^2}B^TPx||^2$$
        $$\dot S(x) \le \gamma^2||u||^2-||y||^2$$
    \end{proof}
    
    \subsection{Exercise 7}
    \begin{Definition}
    A mapping $\Phi: R \rightarrow R, \ u \mapsto \Phi(u)$, belongs to the sector
    \begin{itemize}
        \item $[0,+\infty]$ if $u\Phi(u) \ge 0, \ \forall u \in R$;
        \item $[\alpha,+\infty]$ if $u(\Phi(u)-\alpha u) \ge 0, \ \forall u \in R$ and some $\alpha \in R$;
        \item $[0,\beta]$ if $\Phi(u)(\Phi(u)-\beta u) \le 0, \ \forall u \in R$ and some $\beta \in R$;
        \item $[\alpha,\beta]$ if $(\Phi(u)-\alpha u)(\Phi(u)-\beta u) \le 0, \ \forall u \in R$ and some $\alpha, \beta \in R$;
    \end{itemize}
    Notation: we write, e.g., $\Phi \in [0,+\infty]$.
    \end{Definition}
    
    Problem 1:
    $$\dot x = x^3-kx+u, \ k>0$$
    $$y = x$$
    \begin{proof}
        Take, e.g., $S:R \rightarrow R, x \mapsto \frac{x^2}{2} \ (S \ge 0)$ s.t.
        $$\dot S(x) = x^2(x^2-k)+yu \le yu$$
        whenever $x \in [-\sqrt{k}, \sqrt{k}].$
        
        Let $\bar x \in R$ and take $u = - \bar x^3 + k \bar x$ with init. condition $x(0) = \bar x$, s.t. we have $x(t) = \bar x$ for all $t \ge 0$. If the system is passive, then along this (constant) solution we must have
        $$S(x(t))-S(\bar x) \le \int_0^t u(\tau)y(\tau)d\tau, \ t \ge 0$$ 
        This inequality, however, is violated for $\bar x \notin [-\sqrt{k}, \sqrt{k}]$ and hence $[-\sqrt{k}, \sqrt{k}]$ must be the largest interval.
    \end{proof}
    
    Problem 2:
    $$\dot x = -x+\frac{1}{\beta}h(x)+u, \ \beta>0$$
    $$y = h(x)$$
    $S(x) = \int_0^x h(\sigma) d \sigma, \ h \in [0,\beta]$
    \begin{proof}
        Clearly, we have $S \ge 0$ since $h \in [0, \beta]$.\\
        Moreover,
        $$\dot S(x) = S'(x) \dot x = \dot x \frac{d}{dx}\int_0^x h(\sigma)d\sigma = h(x)\dot x = \frac{1}{\beta}h(x)(h(x)-\beta x) + yu \le yu$$
        since $h \in [0,\beta]$.
    \end{proof}
    
    Problem 3:
    $$H_1: \left\{
                \begin{array}{ll}
                  \dot x_1 = x_2\\
                  \dot x_2 = -x_1 + kx_2 + u, \ k>0 \\
                  y = x_2
                \end{array}
              \right.$$
    \begin{proof}
        Take $S:R^2 \rightarrow R, \ (x_1,x_2) \mapsto \frac{x_1^2}{2}+\frac{x_2^2}{2}$ s.t. $\dot S(x) = uy + ky^2$. \\ 
        Let $u = -\Phi(y), \ \Phi: R \rightarrow R$ satisfying $\Phi \in [l,+\infty]$ for some $l>k \ (\nu_2+\rho_1 > 0)$ s.t. 
        $$\dot S(x) = -y\Phi(y)+ky^2 \le -(l-k)y^2$$
        Since the system $H_1$ is ZSO the origin is GAS.
    \end{proof}
    
    Problem 4:
    \begin{proof}
        Take $S(x) = S_1(x_1)+S_2(x_2)$ s.t.
        $$\dot S(x) \le <u_1,y_1> - \rho_1||y_1||^2 - \nu_1||u_1||^2 + <u_2,y_2> - \rho_2||y_2||^2-\nu_2||u_2||^2$$
        Using that
        $$<u_1,y_1>+<u_2,y_2> = <u-y_2, y_1> + <v+y_1,y_2> = <u,y_1>+<v,y_2>$$
        and
        $$||u_1||^2=||u||^2-2<u,y_2>+||y_2||^2$$
        $$||u_2||^2=||v||^2+2<v,y_1>+||y_1||^2$$
        we obtain \\
        $\dot S(x) = - <\begin{pmatrix} y_1 \\ y_2 \end{pmatrix}, \begin{pmatrix} (\nu_2+\rho_1)I_m & \space \\ \space & (\nu_1+\rho_2)I_m \end{pmatrix} \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}> - <\begin{pmatrix} u \\ v \end{pmatrix}, \begin{pmatrix} \nu_1 I_m & \space \\ \space & \nu_2 I_m \end{pmatrix} \begin{pmatrix} u \\ v \end{pmatrix}> + <\begin{pmatrix} u \\ v \end{pmatrix}, \begin{pmatrix} I_m & 2\nu_1 I_m \\ -2\nu_2 I_m & I_m \end{pmatrix} \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}> \le [Coshi-Schwarz] \le -a||(y_1,y_2)||^2+b||(u,v)||||(y_1,y_2)||+c||(u,v)||^2$ \\
        with $a = \min \{\nu_2 + \rho_1, \nu_1+\rho_2\} > 0, \ b = ||N|| \ge 0$ and $c = ||M|| \ge 0$. \\
        Hence, \\
        $\dot S(x) \le - \frac{1}{2a}(b||(u,v)||-a||(y_1,y_2)||)^2 + \frac{b^2}{2a}||(u,v)||^2-\frac{a}{2}||(y_1,y_2)||^2+c||(u,v)||^2 \le \frac{b^2+2ac}{2a}||(u,v)||^2-\frac{a}{2}||(y_1,y_2)||^2$
    \end{proof}
    
    Problem 5:
    \begin{proof}
        Take $V(x) = <x,Px>$ s.t.
        $$\dot V(x) = <x, (PA+A^TP)x>-2\Phi(y)<x,PB>$$
        Add and subtract $2\Phi(y)^2$ and $2\Phi(y)\beta Cx$ yields \\
        $\dot V(x) = - \varepsilon <x,Px> - <x,L^TLx> - 2\Phi(y)<x,PB-\beta C^T> - 2\Phi(y)^2 + 2\Phi(y)(\Phi(y)-\beta y) = - \varepsilon <x,Px> - |Lx-\sqrt{2}\Phi(y)|^2+2\Phi(y)(\Phi(y)-\beta y) \le - \varepsilon <x,Px>$.
    \end{proof}

\subsection{Exercise 8}

Problem 1:\\
Show that if $\Phi : [0,+\inf) \rightarrow R$ and $\Phi \in L_1 \cap L_{\infty}$, then $\Phi \in L_p \ \forall p \in [1,+\infty]$.
\begin{proof}
    Holder inequality:\\
    Let $p,q \in [1,+\infty], \ \frac{1}{p}+\frac{1}{q}=1$.
    If $f \in L_p$ and $g \in L_q$, then $fg \in L_1$ with
    $$||fg||_{L_1} \le ||f||_{L_p}||g||_{L_q}$$
    Convention: If $p = +\infty \ (q = +\infty)$, then $\frac{1}{p}=0 \ (\frac{1}{q}=0)$. \\
    Let $p \in (1, +\infty).$ We have
    $$(||\Phi||^p_{L_p}=)\int_0^{\infty}|\Phi(t)|^pdt = \int_0^{\infty}|\Phi(t)\Phi(t)^{p-1}|dt \ \le [HE] \le ||\Phi||_{L_1}||\Phi||_{L_{\infty}}^{p-1}$$
    Hence, $\Phi \in L_p$ for any $p \in [1,+\infty)$
\end{proof}

Problem 2:
\begin{proof}
    b) $\Phi_2 = \frac{1}{t+1}$\\
    For $p \in \{1,2\}$, we have
    $$\int_0^{\infty}|\Phi_2(t)|^pdt = \lim_{T \rightarrow +\infty} \int_0^T \frac{1}{(t+1)^p}dt = \left\{\begin{array}{ll}
        \lim_{T \rightarrow +\infty} [\ln(t+1)]|^T_0 = +\infty, \ p=1 \\
        \lim_{T \rightarrow +\infty} [-\frac{1}{t+1}]|^T_0 < +\infty, \ p=2 
    \end{array} \right.$$
    s.t. $\Phi_2 \in L_1$, but $\Phi_2 \in L_2$.\\
    Moreover, 
    $$\sup_{t \ge 0} |\Phi_2(t)|=\sup_{t \ge 0} |\frac{1}{t+1}| = 1 < +\infty$$
    s.t $\Phi_2 \in L_{\infty}$.
\end{proof}

Problem 3:
\begin{proof}
    Take $v=\frac{u}{||u||_{l_p}}, \ u \neq 0$, s.t. $v \in L_p$ and $||v||_{L_p}=1$.\\
    Then
    $$||Hv||_{L_p}=||H\frac{u}{||u||_{l_p}}||_{L_p}=[H - linear]=||\frac{1}{||u||_{l_p}}Hu||_{L_p}=\frac{1}{||u||_{l_p}}||Hu||_{L_p}$$
\end{proof}

Problem 4:
Let $\Phi:[0,+\infty) \rightarrow R$ be defined by $\Phi(t)=t$. Show that $\Phi \in L^e_p$ for any $p \in [1, +\infty]$.
\begin{proof}
    Let $p \in [1, +\infty)$ and fix some $T \ge 0$. Then
    $$(||\Phi_T||^p_{L_p}=)\int^{\infty}_0|\Phi_T(t)|^pdt = \int^T_0|\Phi(t)|^pdt = \int^T_0|t|^pdt = \frac{t^{p+1}}{p+1}|^T_0 = \frac{T^{p+1}}{p+1} < +\infty$$
    Moreover, 
    $$||\Phi_T||_{L_{\infty}}=\sup_{t \ge 0} |\Phi_T(t)|=\sup_{t \in [0,T]} |\Phi(t)|=T < +\infty$$
    $\implies \Phi \in L^e_p \ \forall p \in [1,+\infty]$.
\end{proof}

Problem 5:
\begin{proof}
    $\Longrightarrow$: \\
    Take $u,v \in L^e_p$ s.t. $v_T=u_T$ for some $T \ge 0$. Then, by causality of $H$,
    $$H(u)_T = H(u_T)_T, \ H(v)_T = H(v_T)_T$$
    Since $u_T=v_T$, ot follows $H(u)_T = H(v)_T$.\\
    $\Longleftarrow$: \\
    Take $u \in L^e_p$ and consider $v=u_T$ for some $T \ge 0$. Noting that $v_T = (u_T)_T=u_T$, we have
    $$H(u)_T=H(v)_T=H(u_T)_T$$
\end{proof}

Problem 6:
\begin{proof}
    Let $u \in L^e_{\infty}$ and $T \ge 0$ s.t. for any $0 \le t \le T$
    \begin{multline*} 
        |y_T(t)| \le \int_0^t |h(t-\tau)||u(t)|d\tau \le \sup_{\tau \in [0,T]} |u(\tau)| \int^t_0|h(t-\tau)|d\tau = [\sigma = t - \tau]  = \\ = \sup_{\tau \in [0,T]} |u(\tau)| \int^t_0|h(\sigma)|d\sigma \le \sup_{\tau \in [0,T]} |u(\tau)|( \int^t_0|h|+\int^{\infty}_t|h|) \dots
    \end{multline*}
\end{proof}

\subsection{Exercise 9}

Problem 1:
\begin{proof}
    Let $H_2:L^e_P \rightarrow L^e_p$ be defined by $H_2(e_2)=\frac{1}{2\gamma}e_2$. \\
    Using that $y_2=H_2(e_2)$, it follows
    $$||(y_2)_T||_{L_p}=\frac{1}{2\gamma}||(e_2)_T||_{L_2}, \ \forall e_2 \in L^e_p, \ \forall T \ge 0$$
    Since $\gamma_1 \gamma_2 = \gamma \frac{1}{2\gamma} = \frac{1}{2} < 1$, the SGT reveals that $y \in L_p$ whenever $u \in L_p$.
\end{proof}

Problem 2:
\begin{proof}
    Let $e_2 \in L^e_{\infty}$ and $T \ge 0$ s.t. $y_2=H_2(e_2)$. Then
    $$(||(y_2)_T||^2_{L_2}=) \int^T_0|y_2(t)|^2dt \le ess \sup_{t \in [0,T]} |y_2(t)| \int_0^T |y_2(t)|dt = ||(y_2)_T||_{L_\infty}||(y_2)_T||_{L_1} \le \delta \varepsilon ||(e_2)_T||^2_{L_\infty}$$
    Hence,
    $$||(y_2)_T||_{L_2} \le \sqrt{\delta \varepsilon}||(e_2)_T||_{L_{\infty}}, \ \forall e_2 \in L^e_{\infty}, \forall T \ge 0$$
    for any $u \in L^e_2$ and $T \ge 0$ (with $y=y_2$),
    $$||y_T||_{L_2} \le \sqrt{\delta \varepsilon}||(y_1)_T||_{L_{\infty}} \le \gamma \sqrt{\delta \varepsilon} ||(e_1)_T||_{L_2} \le \gamma \sqrt{\delta \varepsilon} ||u_T||_{L_2} + \gamma \sqrt{\delta \varepsilon} ||y_T||_{L_2}$$
    s.t.
    $$(1-\gamma \sqrt{\delta \varepsilon})||y_T||_{L_2} \le \gamma \sqrt{\delta \varepsilon} ||u_T||_{L_2}$$
    If $\gamma \sqrt{\delta \varepsilon} < 1$, then the SGT reveals that $y \in L_2$ whenever $u \in L_2$.
\end{proof}

Problem 3:
\begin{proof}
    For any $u \in L^e_2$ and $T \ge 0$, we have
    $$<u_T,y_T>_{L_2} = <u_T,h(x)_T>_{L_2} = <a \dot{x}_T+x_T,h(x)_T>_{L_2} = a \int_0^T h(x(t)) \dot{x}(t)dt + \int_0^T x(t)h(x(t))dt$$
    Since $h \in [0, +\infty]$, i.e. $xh(x) \ge 0, \ \forall x \in R$, we have $\int_0^Tx(t)h(x(t))dt \ge 0$.\\
    Now, $\Phi: R \rightarrow R$ be defined by $\Phi(x) = \int_0^x h(\sigma)d\sigma$. \\
    Clearly, $\Phi(x) \ge 0$ for all $x \in R$.\\
    It follows that
    $$a \int_0^Th(x(t)) \dot{x}(t) dt = a \int_{x(0)}^{x(T)}h(\sigma)d\sigma = a(\Phi(x(T))-\Phi(x(0))) \ge -a\Phi(x(0)) =: \beta$$
    Hence, the system is passive ($<u_T,y_T>_{L_2} \ge - \beta, \ \forall u \in L^e_2, \ \forall T \ge 0$).
\end{proof}

Problem 4:
\begin{proof}
    Since $H_1$ is passive (with zero bias ($\beta = 0$)), it follows
    $$<(e_1)_T,(y_1)_T>_{L_2} \ge 0, \ \forall e_1 \in L_2^e, \ \forall T \ge 0.$$
    Using that
     $$<(e_2)_T,(y_2)_T>_{L_2} \ge \delta ||(e_2)_T||^2_{L_2}, \ \forall e_2 \in L_2^e, \ \forall T \ge 0,$$
    we have for $u \in L_2^e$ and $T \ge 0$ with $y=y_1$,
    $$<u_T,y_T>_{L_2} = <(e_1)_T,(y_1)_T>_{L_2} + <(e_2)_T,(y_2)_T>_{L_2} \ge \delta ||y_T||^2_{L_2}.$$
    Using Caschy-Schwarz
    $$||y_T||_{L_2}||u_T||_{L_2} \ge |<u_T,y_T>_{L_2}| \ge <u_T,y_T>_{L_2} \ge \delta ||y_T||^2_{L_2}$$
    s.t.
    $$||y_T||_{L_2} \le \frac{1}{\delta}||u_T||_{L_2}$$
    Since $u \in L_2$, passing to the limit, as $T \rightarrow \infty$, reveals $y \in L_2$.
\end{proof}